{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**\n",
    "\n",
    "* [Task](#task)\n",
    "* [Naive Bayes](#NB)\n",
    "    * [Feature function](#ff)\n",
    "    * [MLE](#MLE)\n",
    "    * [Evaluation](#eval)\n",
    "\n",
    "    \n",
    "**Table of Exercises**\n",
    "\n",
    "\n",
    "* [Exercise 5-1](#ex5-1) (-/1)\n",
    "* [Exercise 5-2](#ex5-2) (-/2)\n",
    "* [Exercise 5-3](#ex5-3) (-/3)\n",
    "* [Exercise 5-4](#ex5-4) (-/2)\n",
    "* [Exercise 5-5](#ex5-5) (-/4)\n",
    "\n",
    "\n",
    "\n",
    "**General notes**\n",
    "\n",
    "* In this notebook you are expected to use $\\LaTeX$. \n",
    "* Use python3.\n",
    "* Use NLTK to read annotated data.\n",
    "* **Document your code**: TAs are more likely to understand the steps if you document them. If you don't, it's also difficult to give you partial points for exercises that are not completely correct.\n",
    "\n",
    "After completing this lab you should be able to \n",
    "\n",
    "* develop Naive Bayes text classifiers\n",
    "* estimate parameters via MLE\n",
    "* predict and evaluate models using precision/recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"task\"> Task\n",
    "\n",
    "We will be looking into binary sentiment analysis where we have to decide whether a document $x$ (a list of tokens) is positive (class $y=1$) or negative (class $y=0$) towards a subject.\n",
    "\n",
    "The dataset we will use comes from NLTK [nltk.corpus.sentence_polarity](http://www.nltk.org/howto/corpus.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import sentence_polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains 5331 positive and 5331 negative sentences, which you can obtain as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sents = sentence_polarity.sents(categories='pos')\n",
    "neg_sents = sentence_polarity.sents(categories='neg')\n",
    "print(len(pos_sents), 'positive sentences such as:\\n', ' '.join(pos_sents[0]))\n",
    "print(len(neg_sents), 'negative sentences such as:\\n', ' '.join(neg_sents[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the first 4000 sentences from each class for training, the next 331 for development, and the last 1000 for test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_pos = pos_sents[:4000]\n",
    "training_neg = neg_sents[:4000]\n",
    "dev_pos = pos_sents[4000:4331]\n",
    "dev_neg = neg_sents[4000:4331]\n",
    "test_pos = pos_sents[4331:]\n",
    "test_neg = neg_sents[4331:]\n",
    "print('Training: %d pos and %d neg' % (len(training_pos), len(training_neg)))\n",
    "print('Development: %d pos and %d neg' % (len(dev_pos), len(dev_neg)))\n",
    "print('Test: %d pos and %d neg' % (len(test_pos), len(test_neg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_docs = training_pos + training_neg\n",
    "dev_docs = dev_pos + dev_neg\n",
    "test_docs = test_pos + test_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"NB\"> Naive Bayes\n",
    "\n",
    "\n",
    "Feature-rich models are used to model the distribution $P_{Y|X}(y|x)$ of a target variable $y$ conditioned on some high-dimensional data $x$.\n",
    "\n",
    "One way of doing it is to summarise aspects of $x$ that are relevant to the problem by means of a feature function which returns a vector in some subset of $\\mathbb R^D$. For example, this feature function may retain sentiment words in $x$ or some other important aspects of the input. Then instead of modelling $P_{Y|X}(y|x)$ we can, for example, model $P_{Y|F_1^n}(y|f_1^n)$ where we condition on a collection of $n$ features instead.\n",
    "\n",
    "Conditioning on features of the input, rather than the input directly, does not address the problem on its own, that is, the conditioning context remains high-dimensional. But here is where we can use probability calculus and independence assumptions to make our task simpler.\n",
    "\n",
    "We can use Bayes rule to invert this conditional:\n",
    "\n",
    "\\begin{align}\n",
    "(1) \\quad P_{Y|F_1^n}(y|f_1^n) = \\frac{P_Y(y)P_{F_1^n|Y}(f_1^n|y)}{P_{F_1^n}(f_1^n)}\n",
    "\\end{align}\n",
    "\n",
    "Now note that the numerator has a conditional where the high-dimensional feature representation of the input is modelled from the target class. That is a problem we can address by making conditional independence assumptions. In particular, by making $F_i$ independent on every other $F_j$ with $i \\neq j$ given the target label $y$ we can simplify the problem a lot. We denote this by $F_i \\perp F_j \\mid y$ for $i\\neq j$. Equation (2) shows the resulting model:\n",
    "\n",
    "\\begin{align}\n",
    "(2) \\quad P_{Y|F_1^n}(y|f_1^n) \\overset{\\text{ind}}{=} \\frac{P_Y(y)\\prod_{i=1}^n P_{F|Y}(f_i|y)}{P_{F_1^n}(f_1^n)}\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "Note that we have to model fairly small cpds now:\n",
    "* a *prior* distribution over classes $P_Y(y)$ \n",
    "* a set of cpds $P_{F|Y}$, one per class, over the possible features (these distributions are also called likelihoods, but do not confuse it with the *likelihood function* which is a function of parameters of a statistical model for fixed data)\n",
    "* the denominator can be inferred by marginalisation, see Equation (3)\n",
    "\n",
    "\\begin{align}\n",
    "(2) \\quad P_{F_1^n}(f_1^n) = \\sum_{y \\in \\mathcal Y} P_{YF_1^n}(y, f_1^n) = \\sum_{y \\in \\mathcal Y} P_{Y}(y)P_{F_1^n|Y}(f_1^n|y) = \\sum_{y \\in \\mathcal Y} P_{Y}(y) \\prod_{i=1}^n P_{F|Y}(f_i|y)\n",
    "\\end{align}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"ff\"> Feature function\n",
    "\n",
    "An important part of a feature-rich model such as Naive Bayes (NB) classifiers is the *feature function*. Here we will develop one. \n",
    "\n",
    "In NB classification, features are themselves random variables defined over a certain set $\\mathcal F$. We need to first determine this set. In this notebook we will focus on *unigram features*, that is, features defined at the token level.\n",
    "\n",
    "We will take every token that occurs more than a pre-specified number of times as a potential feature.\n",
    "\n",
    "Here is an example of how you can do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "def make_unigram_feature_set(documents, min_freq=1, mark_negation=False):\n",
    "    \"\"\"\n",
    "    This function goes through a corpus and retains all candidate unigram features\n",
    "     making a feature set. \n",
    "    \n",
    "    :param documents: all documents, each a list of words\n",
    "    :param min_freq: minimum frequency of a token for it to be part of the feature set\n",
    "    :param mark_negation: **IGNORE THIS FOR NOW**\n",
    "    :returns: unigram feature set\n",
    "    \"\"\"\n",
    "    counter = Counter()\n",
    "    for doc in documents:\n",
    "        counter.update(doc)\n",
    "    features = []\n",
    "    for f, n in counter.most_common():\n",
    "        if n >= min_freq:\n",
    "            features.append(f)\n",
    "        else:\n",
    "            break\n",
    "    return frozenset(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ex5-1\" style=\"color:red\">**Exercise 5-1**</a> **[1 points]** Modify `make_unigram_feature_set` to optionally pre-process documents by marking words in the scope of a negation with the suffix `_NEG`. For example,  `I am not sure I like the acting` becomes `I am not sure_NEG I_NEG like_NEG the_NEG acting_NEG`. You can use NLTK support for that, see for example, `nltk.sentiment.util.mark_negation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can check python documentation by using the following syntax\n",
    "from nltk.sentiment import util\n",
    "util.mark_negation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def make_unigram_feature_set(documents, min_freq=1, mark_negation=False):\n",
    "    \"\"\"\n",
    "    This function goes through a corpus and retains all candidate unigram features\n",
    "     making a feature set. Optionally, it can also preprocess the corpus annotating\n",
    "     with _NEG words that are in the scope of a negation (using NLTK helper functions).\n",
    "    \n",
    "    :param documents: all documents, each a list of words\n",
    "    :param min_freq: minimum frequency of a token for it to be part of the feature set\n",
    "    :param mark_negation: whether to preprocess the document using NLTK's nltk.sentiment.util.mark_negation\n",
    "        see the documentation `nltk.sentiment.util.mark_negation?`\n",
    "    :returns: unigram feature set\n",
    "    \"\"\"\n",
    "    pass\n",
    "    # ***TYPE YOUR SOLUTION HERE***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is just some helper code for better visualization of examples\n",
    "def inspect_set(input_set, k=5, neg=False):\n",
    "    \"\"\"\n",
    "    Helper function to inspect a few elements in a set of features\n",
    "    \n",
    "    :param input_set: a set of features\n",
    "    :param k: how many elements to select\n",
    "    :param neg: return `*_NEG` features only\n",
    "    :returns: up to k elements \n",
    "    \"\"\"\n",
    "    selected = set()\n",
    "    for w in input_set:\n",
    "        if len(selected) < k:            \n",
    "            if not neg:\n",
    "                selected.add(w)\n",
    "            elif '_NEG' in w:\n",
    "                selected.add(w)\n",
    "        else:\n",
    "            break\n",
    "    return selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some of the features (without marking negation):\n",
    "\n",
    "```python\n",
    ">>> unigram_features = make_unigram_feature_set(training_docs+dev_docs, min_freq=2)\n",
    ">>> print(len(unigram_features), 'features such as:\\n', inspect_set(unigram_features))\n",
    "```\n",
    "```\n",
    "9059 features such as:\n",
    " {'white', 'fearless', 'ear', 'tempting', 'meat'}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unigram_features = make_unigram_feature_set(training_docs+dev_docs, min_freq=2)\n",
    "print(len(unigram_features), 'features such as:\\n', inspect_set(unigram_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some of the features with pre-processing negation scope.\n",
    "\n",
    "```python\n",
    ">>> unigram_features_with_negation = make_unigram_feature_set(training_docs+dev_docs, min_freq=2, mark_negation=True)\n",
    ">>> print(len(unigram_features_with_negation), 'features such as:\\n', \n",
    "      inspect_set(unigram_features_with_negation), \n",
    "      '\\nand:\\n', inspect_set(unigram_features_with_negation, neg=True))\n",
    "```\n",
    "\n",
    "```\n",
    "10143 features such as:\n",
    " {'white', 'message_NEG', 'fearless', 'ear', 'tempting'} \n",
    "and:\n",
    " {'ticket_NEG', 'message_NEG', 'street_NEG', 'determined_NEG', 'stereotype_NEG'}     \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_features_with_negation = make_unigram_feature_set(training_docs+dev_docs, min_freq=2, mark_negation=True)\n",
    "print(len(unigram_features_with_negation), 'features such as:\\n', \n",
    "      inspect_set(unigram_features_with_negation), \n",
    "      '\\nand:\\n', inspect_set(unigram_features_with_negation, neg=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know which features will form the basis of our classifier, we need to implement a feature function. Here we call it a feature map (as we will be using a python dictionary).\n",
    "\n",
    "In NB classification only the features that occur in an input matter for classification, thus we use a dictionary that maps features to their values if they occur and not otherwise.\n",
    "\n",
    "This function should take a document $x$ and produce a dict where `f` (a feature) is either 1 (for binary features) or a count (for count features). For the purpose of readability we like to represent features with strings, for example:\n",
    "\n",
    "* `contains(like) = 1` means that the input contains the word `like`\n",
    "* `count(like) = 3` means that the input contains 3 occurrences of the word `like`\n",
    "* `EMPTY() = 1` means that the input contains no known feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ex5-2\" style=\"color:red\">**Exercise 5-2**</a> **[2 points]** Read the documentation below and implement the feature function described."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def make_feature_map(document, feature_set, \n",
    "                     binary=True, \n",
    "                     mark_negation=False):\n",
    "    \"\"\"\n",
    "    This function takes a document, possibly pre-processes it by marking words in the scope of negation, \n",
    "     and constructs a dict indicating which features in `feature_set` fire. Features may be binary, \n",
    "     flagging occurrence, or integer, indicating the number of occurrences.\n",
    "     If no feature can be extracted, a special feature is fired, namely 'EMPTY()'.\n",
    "     \n",
    "    :param document: a list of words\n",
    "    :param feature_set: set of features we are looking for\n",
    "    :param binary: whether we are indicating presence or counting features in feature_set\n",
    "    :param mark_negation: whether we should apply NLTK's mark_negation to document before applying the feature function\n",
    "    :returns: dict with entries 'contains(f)=1/0' for binary features or 'count(f)=n' for count features\n",
    "    \"\"\"\n",
    "    pass\n",
    "    # ***TYPE YOUR SOLUTION HERE***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some outputs for you to check your implementation:\n",
    "\n",
    "```python\n",
    ">>> make_feature_map(pos_sents[7], unigram_features_with_negation, \n",
    "                 binary=True, mark_negation=True)\n",
    "```\n",
    "```\n",
    "defaultdict(float,\n",
    "            {'contains(.)': 1.0,\n",
    "             'contains(ever_NEG)': 1.0,\n",
    "             'contains(good_NEG)': 1.0,\n",
    "             'contains(has_NEG)': 1.0,\n",
    "             'contains(hell_NEG)': 1.0,\n",
    "             'contains(is_NEG)': 1.0,\n",
    "             'contains(literally_NEG)': 1.0,\n",
    "             'contains(made_NEG)': 1.0,\n",
    "             'contains(more_NEG)': 1.0,\n",
    "             'contains(no)': 1.0,\n",
    "             'contains(perhaps)': 1.0,\n",
    "             'contains(picture_NEG)': 1.0,\n",
    "             'contains(road_NEG)': 1.0,\n",
    "             'contains(that_NEG)': 1.0,\n",
    "             'contains(the_NEG)': 1.0,\n",
    "             'contains(to_NEG)': 1.0,\n",
    "             'contains(with_NEG)': 1.0})\n",
    "```\n",
    "```python\n",
    ">>> make_feature_map(['AKSJDHAU'], unigram_features_with_negation, \n",
    "                 binary=True, mark_negation=True)\n",
    "```\n",
    "```\n",
    "defaultdict(float, {'EMPTY()': 1.0})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"MLE\"> MLE\n",
    "\n",
    "Now you will estimate the cpds involved in NB classification. We use a balanced dataset over two classes (positive and negative), so there's no need to compute $P_Y(y)$, it would simply be $0.5$ per class.\n",
    "\n",
    "You should simply implement cpds for $P_{F|Y}$, that is, exactly $2$ cpds via MLE and you should use Laplace-$\\alpha$ smoothing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ex5-3\" style=\"color:red\">**Exercise 5-3**</a> **[3 points]** Check the documentation below and complete the code for the NB classifier. You will need to implement\n",
    "\n",
    "* estimation of cpds $P_{F|Y}$ with Laplace smoothing  (1 point) \n",
    "* the `classify` method (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def make_cpd(raw_counts, alpha, v):\n",
    "    \"\"\"\n",
    "    This converts a dictionary of raw counts into a cpd.\n",
    "\n",
    "    :param raw_counts: dict where a key is a feature and a value is its counts (without pseudo counts)\n",
    "        this should already include the 'EMPTY()' feature\n",
    "    :param alpha: how many pseudo counts should we add per observation\n",
    "    :param v: the size of the feature set (already including the 'EMPTY()' feature)\n",
    "    :returns: a cpd as a dict where a key is a feature and a value is its smoothed probability\n",
    "    \"\"\"\n",
    "    pass\n",
    "    # ***TYPE YOUR SOLUTION***\n",
    "\n",
    "class NaiveBayesClassifier:\n",
    "    \n",
    "    def __init__(self, training_pos, training_neg, binary, mark_negation, alpha=0.1, min_freq=2):\n",
    "        \"\"\"\n",
    "        :param training_pos: positive documents\n",
    "            a document is a list of tokens\n",
    "        :param training_neg: negative documents\n",
    "            a document is a list of tokens\n",
    "        :param binary: whether we are using binary or count features\n",
    "        :param mark_negation: whether we are pre-processing words in negation scope\n",
    "        :param alpha: Laplace smooth pseudo count\n",
    "        :param min_freq: minimum frequency of a token for it to be considered a feature\n",
    "        \"\"\"\n",
    "                \n",
    "        # Make feature set\n",
    "        print('Extracting features:')\n",
    "        feature_set = make_unigram_feature_set(\n",
    "            training_pos + training_neg,  # we use a concatenation of positive and negative training instances\n",
    "            min_freq=min_freq, \n",
    "            mark_negation=mark_negation)\n",
    "        \n",
    "        print(' %d features' % len(feature_set))\n",
    "                \n",
    "        # Estimate model: 1/2) count        \n",
    "        print('MLE: counting')        \n",
    "        counts = [defaultdict(float), defaultdict(float)]\n",
    "        for docs, y in [(training_pos, 1), (training_neg, 0)]:\n",
    "            for doc in docs:  # for each document\n",
    "                # we extract features\n",
    "                fmap = make_feature_map(doc, \n",
    "                                        feature_set, \n",
    "                                        binary=binary, \n",
    "                                        mark_negation=mark_negation)\n",
    "                # and gather counts for the pair (y, f)\n",
    "                for f, n in fmap.items():\n",
    "                    counts[y][f] += n  \n",
    "                                \n",
    "        # 2/2) Laplace-1 MLE\n",
    "        #  we put EMPTY() is in the support\n",
    "        print('MLE: smoothing')\n",
    "        counts[0]['EMPTY()'] += 0\n",
    "        counts[1]['EMPTY()'] += 0\n",
    "        # and compute cpds using Laplace smoothing\n",
    "        self._cpds = [\n",
    "            make_cpd(counts[0], alpha, len(feature_set) + 1),  # we add 1 because we want EMPTY() to add towards total\n",
    "            make_cpd(counts[1], alpha, len(feature_set) + 1)]\n",
    "        print('MLE: done')\n",
    "            \n",
    "        # Store data\n",
    "        self._binary = binary\n",
    "        self._mark_negation = mark_negation\n",
    "        self._alpha = alpha\n",
    "        self._feature_set = feature_set\n",
    "            \n",
    "    def get_log_parameter(self, f, y):\n",
    "        \"\"\"Returns log P(f|y)\"\"\"\n",
    "        return np.log(self._cpds[y].get(f, self._cpds[y]['EMPTY()']))\n",
    "        \n",
    "    def classify(self, doc):\n",
    "        \"\"\"\n",
    "        This function classifies a document by extracting features <f_1...f_n> for it \n",
    "         and then computing \n",
    "            log P(<f_1...f_n>|Y=0) and log P(<f_1...f_n>|Y=1)\n",
    "         and finally picking the best (that is, either Y=0 or Y=1).\n",
    "        \n",
    "        :param doc: a list of tokens\n",
    "        :returns: 0 or 1 (the argmax of log P(<f_1...f_n>|y))\n",
    "        \"\"\"\n",
    "        pass\n",
    "        # ***TYPE YOUR SOLUTION***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how you should use the classifier:\n",
    "\n",
    "```python\n",
    ">>> classifier1 = NaiveBayesClassifier(\n",
    "    training_pos, training_neg, \n",
    "    binary=True, mark_negation=False,\n",
    "    alpha=1., min_freq=2)\n",
    "```\n",
    "```\n",
    "Extracting features:\n",
    " 8577 features\n",
    "MLE: counting\n",
    "MLE: smoothing\n",
    "MLE: done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"eval\"> Evaluation\n",
    "\n",
    "We evaluate binary classifiers on precision, recall, F1 and accuracy. See [Figure 4.4](https://web.stanford.edu/~jurafsky/slp3/4.pdf) and complete the code below:\n",
    "\n",
    "<a name=\"ex5-4\" style=\"color:red\">**Exercise 5-4**</a> **[2 points]** Classify all documents in a dev set and compute the quantities in [Figure 4.4](https://web.stanford.edu/~jurafsky/slp3/4.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(classifier, pos_docs, neg_docs):\n",
    "    \"\"\"\n",
    "    :param classifier: an NaiveBayesClassifier object\n",
    "    :param pos_docs: positive documents\n",
    "    :param neg_docs: negative documents\n",
    "    :returns: a dictionary containing the number of\n",
    "        * true positives\n",
    "        * true negatives\n",
    "        * false positives\n",
    "        * false negatives\n",
    "     as well as \n",
    "        * accuracy\n",
    "        * precision\n",
    "        * recall \n",
    "        * and [F1](https://en.wikipedia.org/wiki/F1_score)\n",
    "    \"\"\"\n",
    "    pass\n",
    "    # ***TYPE YOUR SOLUTION***\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, our implementation yields:\n",
    "\n",
    "```python\n",
    ">>> classifier1 = NaiveBayesClassifier(\n",
    "    training_pos, training_neg, \n",
    "    binary=True, mark_negation=False,\n",
    "    alpha=1., min_freq=2)\n",
    "```\n",
    "```\n",
    "Extracting features:\n",
    " 8577 features\n",
    "MLE: counting\n",
    "MLE: smoothing\n",
    "MLE: done\n",
    "```\n",
    "```python\n",
    ">>> dev_metrics1 = evaluate_model(classifier1, dev_pos, dev_neg)\n",
    ">>> print('Development')\n",
    ">>> print('TP %d TN %d FP %d FN %d' % (dev_metrics1['TP'], dev_metrics1['TN'], dev_metrics1['FP'], dev_metrics1['FN']))\n",
    ">>> print('P %.4f R %.4f A %.4f F1 %.4f' % (dev_metrics1['P'], dev_metrics1['R'], dev_metrics1['A'], dev_metrics1['F1']))\n",
    "```\n",
    "```\n",
    "Development\n",
    "TP 239 TN 268 FP 63 FN 92\n",
    "P 0.7914 R 0.7221 A 0.7659 F1 0.7551\n",
    "```\n",
    "```python\n",
    ">>> classifier2 = NaiveBayesClassifier(\n",
    "    training_pos, training_neg, \n",
    "    binary=True, mark_negation=True,\n",
    "    alpha=1., min_freq=2)\n",
    "```\n",
    "```\n",
    "Extracting features:\n",
    " 9581 features\n",
    "MLE: counting\n",
    "MLE: smoothing\n",
    "MLE: done  \n",
    "```\n",
    "```python\n",
    ">>> dev_metrics2 = evaluate_model(classifier2, dev_pos, dev_neg)\n",
    ">>> print('Development')\n",
    ">>> print('TP %d TN %d FP %d FN %d' % (dev_metrics2['TP'], dev_metrics2['TN'], dev_metrics2['FP'], dev_metrics2['FN']))\n",
    ">>> print('P %.4f R %.4f A %.4f F1 %.4f' % (dev_metrics2['P'], dev_metrics2['R'], dev_metrics2['A'], dev_metrics2['F1']))\n",
    "```\n",
    "```\n",
    "Development\n",
    "TP 248 TN 273 FP 58 FN 83\n",
    "P 0.8105 R 0.7492 A 0.7870 F1 0.7786\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ex5-5\" style=\"color:red\">**Exercise 5-5**</a> **[4 points]** Use the dev set to choose the best configuration of \n",
    "\n",
    "* alpha (try values like 0.1, 0.5, 1.)\n",
    "* and binary vs count\n",
    "\n",
    "for a model that marks negation and one that does not. \n",
    "\n",
    "Then report performance on test set for your best model in each case. \n",
    "\n",
    "Points:\n",
    "* 3 points for the search on dev set\n",
    "* 1 point for the table of test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
